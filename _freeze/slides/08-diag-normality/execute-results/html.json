{
  "hash": "663e51c96054f20f714e35fb01934827",
  "result": {
    "markdown": "---\ntitle: \"Regression Diagnostics: Normality ðŸ“–\"\nsubtitle: \"MATH 4780 / MSSC 5780 Regression Analysis\"\nauthor: \"Dr. Cheng-Han Yu <br> Department of Mathematical and Statistical Sciences <br> Marquette University\"\n# date: \"October 27 2023\"\n# macros: _macros.tex # import a list of TeX/LaTeX definitions\nformat: \n  revealjs:\n    code-line-numbers: true\n    #     - \"macros.tex\"\n    html-math-method:\n      method: mathjax\n      url: \"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\"\n    # include-in-header:\n    highlight-style: arrow\n    code-block-bg: true\n    self-contained: false\n    slide-number: c/t    \n    incremental: false\n    width: 1800\n    height: 1000\n    margin: 0.05\n    logo: \"https://upload.wikimedia.org/wikipedia/commons/e/e8/Marquette_Golden_Eagles_logo.svg\"\n    footer: \"[math4780-f23.github.io/website](https://math4780-f23.github.io/website/)\"\n    theme: [\"simple\", \"slides.scss\"]\n    multiplex: false\n    code-link: true\n    fig-cap-location: bottom\n    fig-align: center\n    transition: none ## fade slide convex concave zoom\n    title-slide-attributes:\n      data-background-color: \"#447099\"\n      # data-background-image: images/paper-texture.jpg\n      # data-background-size: cover\n      # data-background-color: \"#698ED5\"\neditor: source\nexecute:\n  freeze: true\n  echo: false\n  purl: true\n---\n\n\n#  {visibility=\"hidden\"}\n\n\\def\\bx{\\mathbf{x}}\n\\def\\bg{\\mathbf{g}}\n\\def\\bw{\\mathbf{w}}\n\\def\\balpha{\\boldsymbol \\alpha}\n\\def\\bbeta{\\boldsymbol \\beta}\n\\def\\beps{\\boldsymbol \\epsilon}\n\\def\\bX{\\mathbf{X}}\n\\def\\by{\\mathbf{y}}\n\\def\\bH{\\mathbf{H}}\n\\def\\bI{\\mathbf{I}}\n\\def\\bS{\\mathbf{S}}\n\\def\\bW{\\mathbf{W}}\n\\def\\T{\\text{T}}\n\\def\\cov{\\mathrm{Cov}}\n\\def\\cor{\\mathrm{Corr}}\n\\def\\var{\\mathrm{Var}}\n\\def\\E{\\mathrm{E}}\n\\def\\bmu{\\boldsymbol \\mu}\n\\DeclareMathOperator*{\\argmin}{arg\\,min}\n\\def\\Trace{\\text{Trace}}\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\n\n\n\n## Assumptions of Linear Regression\n$Y_i= \\beta_0 + \\beta_1X_{i1} + \\beta_2X_{i2} + \\dots + \\beta_kX_{ik} + \\epsilon_i$\n\n:::: {.columns}\n::: {.column width=\"50%\"}\n- $E(Y \\mid X)$ and $X$ are linearly related.\n- $\\small E(\\epsilon_i) = 0$\n- $\\small \\var(\\epsilon_i) = \\sigma^2$\n- $\\small \\cov(\\epsilon_i, \\epsilon_j) = 0$ for all $i \\ne j$.\n- $\\small \\epsilon_i \\stackrel{iid}{\\sim} N(0, \\sigma^2)$ (for statistical inference)\n:::\n\n\n\n::: {.column width=\"50%\"}\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](./images/08-diag-normality/regression_line_sig.png){fig-align='center' width=100%}\n:::\n:::\n\n:::\n::::\n\n\n::: notes\n<!-- - How's your exam? -->\n<!-- - We finished the discussion of SLR and MLR. Remember that our regression models are based on some assumptions. In fact these assumptions are quite restricted. -->\n- So it's not that uncommon to see violation of assumptions.\n- Today, we are going to learn how to check whether those assumptions are valid or satisfied.\n- And probably the following two weeks, if the assumptions are not satisfied, how do we deal with it. OK.\n:::\n\n. . .\n\n::: alert\n- If the assumptions are violated, a different sample could lead to a different conclusion!\n- $R^2$ tells us how good the model is fitted to the data, but says nothing about the correctness of the model.\n- All the inferences are based on the assumption that the model is correct.\n:::\n\n\n\n# Model Adequacy Checking and Correction\n\n<h2> <span style=\"color:red\"> Non-normality</span></h2>\n<h2> Non-constant Error Variance </h2>\n<h2> Non-linearity and Lack of Fit </h2>\n\n::: notes\n\n- This week we are going to learn some methods to correct model inadequacy.\n- We can either transform our data, our use a more general method, called Generalized Least Squares or Weighted Least Squares.\n- $\\epsilon_i \\stackrel{iid}{\\sim} N(0, \\sigma^2)$: **mean 0**, **constant variance**, **normally distributed**, and **uncorrelated**.\n- $E(\\epsilon_i) =0$ implies the function form of the model (**linearity**) is correct.\n\n:::\n\n## Non-normality\n- The central limit theorem assures the validity of inferences based on the least-squares (LS) coefficients in all but small samples.\n\n. . .\n\nWithout normality, \n\n- **Heavier tailed** errors:\n  + LS estimators do not have the **smallest** variance among unbiased estimators.\n  + give rise to **outliers**.\n\n::: notes\nGauss-Markov does not require normality.\n:::\n\n. . .\n\n- **Skewed** errors:\n  + tend to generate outliers in the direction of the skew.\n  + the conditional mean of $y$ given $x$ is not a good measure of center of a highly skewed distribution.\n\n. . .\n\n- **Multimodal** errors:\n  + suggest the omission of one or more categorical regressors.\n  \n  \n::: notes\n- $\\epsilon_i \\stackrel{iid}{\\sim} N(0, \\sigma^2)$: **mean 0**, **constant variance**, **normally distributed**, and **uncorrelated**.\n- The form of the model (**linearity**) and the specification of the predictors are correct. \n- Check model adequacy by residual plots and lack-of-fit tests.\n- Methods for building models when some of the assumptions are violated.\n  + data transformation\n  + generalized least squares (GLS) and weighted least squares (WLS)\n  \n:::\n\n\n## Detecting Nonnormality\n<!-- - Under normality, the R-student residuals $t_i$s have mean *zero* and *equal* variances. -->\n\n- The R-student residuals $t_i \\sim t_{n-p-1}$ if the model assumptions are correct.\n\n- Compare the distribution of the $t_i$s to $t_{n-p-1}$ in QQ plot.\n\n::: notes\n- One way to address the assumption of normality is to compare the distribution of the R-student residuals to $t_{n-p-1}$ in QQ plot.\n:::\n\n. . .\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](./images/08-diag-normality/unnamed-chunk-4-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\n\n## QQ plot of R-Student Residuals Comparing $t_{n-p-1}$\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncar::qqPlot(delivery_lm, id = TRUE, col.lines = \"blue\", \n            reps = 1000, ylab = \"Ordered R-Student Residuals\", pch = 16)\n```\n\n::: {.cell-output-display}\n![](./images/08-diag-normality/unnamed-chunk-5-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n::: notes\n- The `car` package calls the R-student residuals *studentized* residuals.\n- if put lm object, `car::qqPlot` automatically create qqplot for R-student residual comparing with $t_{n-p-1}$ distribution.\n- No severe problem in delivery data\n- id = controls point identification; if FALSE, no points are identified; can be a list of named arguments to the showLabels function; TRUE is equivalent to list(method=\"y\", n=2, cex=1, col=carPalette()[1], location=\"lr\"), which identifies the 2 points with the 2 points with the most extreme verical values â€” studentized residuals for the \"lm\" method.\n:::\n\n## Density plot of R-Student Residuals\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nrstud <- rstudent(delivery_lm)\nhist(rstud, prob = TRUE, breaks = 10, xlab = \"R-Student Residuals\", main = \"\")\nlines(density(rstud, adjust = 2), col = 4, lwd = 2)\n```\n\n::: {.cell-output-display}\n![](./images/08-diag-normality/unnamed-chunk-6-1.png){fig-align='center' width=67%}\n:::\n:::\n\n\n\n::: notes\n- The QQ plot draws attention to the tail behavior of the R-student residuals but is less effective in visualizing their distribution as a whole.\n- Check histogram or smooth density plot of the R-student residuals to get the general shape of the distribution.\n- May be better to add another categorical regressor\n- car::densityPlot(rstud, adjust = 2, xlab = \"R-Student Residuals\")\n:::\n\n\n## Correcting Nonnormality\n\n- A response that is close to normal usually makes the assumption of normal errors more tenable.\n\n- *Heavier tailed* errors:\n  + Use robust regression (Chap 15 in LRA)\n\n- *Skewed* errors:\n  + Transform response data for symmetry\n  \n- *Multimodal* errors:\n  + Add one or more relevant categorical variables.\n\n\n::: alert\nWant the error or the response conditional on $x$s to be like normal after correction.\n:::\n\n\n## Transformation for Symmetry\n\n**Power transformation: $y \\rightarrow y^{\\lambda}$**\n\n  + make the distribution of $y$ more normal, *at least more symmetric*.\n  + $y$ can take on *positive* values only.\n  + $y \\rightarrow \\ln(y)$ for $\\lambda = 0.$\n\n. . .\n\n**Ladder of powers and roots (Tukey, 1977)**:\n\n- No transformation: $\\lambda = 1$\n- **Descending**: *spreads out the __small__ values of $y$ relative to the large values*.\n    + $\\lambda = 1/2$ (square root); $\\lambda = 0$ (natural log); $\\lambda = -1$ (inverse) \n- **Ascending**: *spreads out the __large__ values relative to the small values*.\n    + $\\lambda = 2$ (square); $\\lambda = 3$ (cube) \n\n::: notes\nif $\\lambda$ is descending from $1$ to $-1$, the fransformation increasingly spreads out the small values of $y$ relative to the large values.\n:::\n\n\n. . .\n\n::: alert\nThe order of $y$ is *reversed* if $\\lambda < 0$ is used for power transformation.\n:::\n\n\n## Correcting Skewness by Power Transformation\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](./images/08-diag-normality/unnamed-chunk-8-1.png){fig-align='center' width=78%}\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](./images/08-diag-normality/unnamed-chunk-9-1.png){fig-align='center' width=78%}\n:::\n:::\n\n\n\n\n## Box-Cox Transformation on $y$\n\n\n  \n:::: {.columns}\n\n::: {.column width=\"35%\"}\n\nA modified power transformation by [Box and Cox (1964)](https://www.nuffield.ox.ac.uk/users/cox/cox72.pdf):\n\n$$y^{(\\lambda)} = \\begin{cases}\n    \\frac{y^{\\lambda}-1}{\\lambda},       & \\quad \\lambda \\ne 0\\\\\n    \\ln y,  & \\quad \\lambda = 0\n  \\end{cases}$$\n  \n::: alert\n\n- For all $\\lambda$, $y^{(\\lambda)} = 1$ at $y = 1$.\n- The order of the transformed data $y^{(\\lambda)}$ is the same as that of $y$, even for $\\lambda < 0.$\n\n:::\n:::\n  \n\n\n::: {.column width=\"65%\"}\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](./images/08-diag-normality/unnamed-chunk-10-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n:::\n::::\n\n\n::: notes\n- The derivative w.r.t. $y$ of $y^{(\\lambda)}$ at $y = 1$ is 1 for any $\\lambda$.\n:::\n\n\n## Box-Cox Transformation on $y$: Choose $\\lambda$ Analytically\n\n- The model to be fit is \n$$y_i^{(\\lambda)} = \\beta_0 + \\beta_1x_{i1}+ \\cdots + \\beta_kx_{ik} + \\epsilon_i^*$$\n- Choose $\\lambda$ so that the transformed errors $\\epsilon_i^*$ look as nearly normally distributed as possible.\n\n\n\n## [R Lab]{.pink} [CIA World Factbook Data](https://www.john-fox.ca/RegressionDiagnostics/index.html)\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\n:::: {.columns}\n\n::: {.column width=\"55%\"}\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n```{.my_class600}\n            gdp infant gini health  region\nAlbania    11.1   12.8   34    6.0  Europe\nAlgeria    14.3   21.0   35    5.2  Africa\nArgentina  22.1    9.7   46    8.5 America\nArmenia     7.4   13.5   31    4.5  Europe\nAustralia  46.6    4.4   30    9.1 Oceania\nAustria    45.4    3.5   26   11.5  Europe\nAzerbaijan 17.9   25.7   34    5.4    Asia\nBangladesh  3.4   44.1   32    3.6    Asia\nBelarus    18.2    3.6   27    5.0  Europe\nBelgium    41.7    3.4   26   10.8  Europe\nBenin       1.9   55.7   36    4.5  Africa\nBhutan      7.7   35.9   39    3.8    Asia\n```\n:::\n:::\n\n:::\n\n::: {.column width=\"45%\"}\n- `gdp`: GDP per capita in thousands of U.S. dollars\n- `infant`: Infant mortality rate per 1000 live births\n- `gini`: Gini coefficient for the distribution of family income\n- `health`: Health expenditures as a percentage of GDP\n:::\n::::\n\n\n## [R Lab]{.pink} R-Student Residuals\n\n- See how `gdp`, `health` and `gini` affect `infant`.\n- R-Student residuals are right-skewed, suggesting transforming the response, infant mortality, down the ladder of powers.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nciafit <- lm(infant ~ gdp + health + gini, data = CIA)\nr_stud <- rstudent(ciafit)\ncar::qqPlot(ciafit, id = FALSE)\ncar::densityPlot(r_stud)\n```\n\n::: {.cell-output-display}\n![](./images/08-diag-normality/unnamed-chunk-13-1.png){fig-align='center' width=56%}\n:::\n:::\n\n\n\n## [R Lab]{.pink} Box-Cox Transformation\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"true\"}\nmat <- matrix(r_stud)\nfor (lam in c(0.5, 0, -0.5, -1)) {\n    refit <- update(\n        ciafit, car::bcPower(infant, lam) ~ .\n        )\n    mat <- cbind(rstudent(refit), mat)\n}\ncolnames(mat) <- c(-1, -0.5, \"log\", 0.5, 1)\nboxplot(\n    mat, id = FALSE, \n    xlab = expression(\"Powers,\" ~ lambda),\n    ylab = expression(\n        \"R-Student Residuals for \" \n        ~ Infant ^ (lambda))\n    )\n```\n\n::: {.cell-output-display}\n![](./images/08-diag-normality/boxcox-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n## [R Lab]{.pink} Choose $\\lambda$ Analytically\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsummary(car::powerTransform(ciafit, family = \"bcPower\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```{.my_class600}\nbcPower Transformation to Normality \n   Est Power Rounded Pwr Wald Lwr Bnd Wald Upr Bnd\nY1     -0.22       -0.33        -0.37       -0.072\n\nLikelihood ratio test that transformation parameter is equal to 0\n (log transformation)\n                      LRT df  pval\nLR test, lambda = (0)   8  1 0.005\n\nLikelihood ratio test that no transformation is needed\n                      LRT df   pval\nLR test, lambda = (1) 181  1 <2e-16\n```\n:::\n:::\n\n\n- $\\hat{\\lambda} = -0.22$, and the $95\\%$ CI for $\\lambda$ is $[-0.37, -0.07]$.\n- $\\lambda = 1$ not in the interval, providing support for transforming response.\n- $\\lambda = 0$ (log transformation) is slightly outside the interval.\n\n\n::: notes\n`car::powerTransform()` uses the maximum likelihood-like approach to select a $\\lambda$ estimate, $\\hat{\\lambda}$.\n:::\n\n## Other Issues\n- Apply power transformations to data with zero or negative values by adding a positive constant to the data to make all values positive.\n  + $\\log(y + 10)$ if all $y > -10$.\n  \n. . .\n\n- Power transformations are effective when the ratio of the largest to smallest values is sufficiently large.\n  + If $y_{max}/y_{min} \\approx 1$, power transformations are nearly linear.\n  + Increase the ratio by adding a negative constant, $(y_{max} - c)/(y_{min}-c)$\n\n. . .\n\n- If acceptable, choose log transformation for simple interpretation.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlogciafit <- lm(log(infant) ~ gdp + health + gini, data = CIA)\ncoef(logciafit)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n(Intercept)         gdp      health        gini \n      3.016      -0.044      -0.055       0.022 \n```\n:::\n:::\n\n\n- All else held constant, for one unit increase of `gdp`, the infant mortality rate is expected to be decreased, on average, by 4.3% because $\\exp(-0.044) = 0.957$.\n\n\n::: notes\nHawkins and Weisberg (2017)\n- Skewed conditional distribution of $y$ is not a good measure of center.\n  + Create a model for conditional *median* of the response. (Quantile regression)\n- OLS regression of the original variable  is used to to estimate the expected arithmetic mean and OLS regression of the log transformed outcome variable is to estimated the expected geometric mean of the original variable.\n\n:::\n\n\n<!-- ## Other Issues {visibility=\"hidden\"} -->\n\n<!-- - If acceptable, choose log transformation for simple interpratation. -->\n\n<!-- ```{r} -->\n<!-- logciafit <- lm(log(infant) ~ gdp + health + gini, data = CIA) -->\n<!-- coef(logciafit) -->\n<!-- ``` -->\n\n<!-- - All else held constant, for one unit increase of `gdp`, the infant mortality rate is expected to be decreased, on average, by 4.3% because $\\exp(-0.044) = 0.957$. -->\n\n<!-- ??? -->\n<!-- https://stats.oarc.ucla.edu/other/mult-pkg/faq/general/faqhow-do-i-interpret-a-regression-model-when-some-variables-are-log-transformed/ -->\n<!-- https://data.library.virginia.edu/interpreting-log-transformations-in-a-linear-model/ -->\n<!-- chrome-extension://efaidnbmnnnibpcajpcglclefindmkaj/https://kenbenoit.net/assets/courses/ME104/logmodels2.pdf -->\n\n<!-- https://medium.com/@kyawsawhtoon/log-transformation-purpose-and-interpretation-9444b4b049c9 -->\n\n<!-- https://sites.google.com/site/curtiskephart/ta/econ113/interpreting-beta -->\n\n<!-- https://stats.stackexchange.com/questions/18480/interpretation-of-log-transformed-predictor-and-or-response -->\n\n<!-- https://zief0002.github.io/book-8252/nonlinearity-log-transforming-the-predictor.html -->\n\n",
    "supporting": [
      "08-diag-normality_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}