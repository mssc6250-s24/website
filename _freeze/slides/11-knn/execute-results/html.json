{
  "hash": "8ad1d264e6094b9b5d873c9f6b735866",
  "result": {
    "markdown": "---\ntitle: 'K-nearest Neighbors `<svg aria-hidden=\"true\" role=\"img\" viewBox=\"0 0 640 512\" style=\"height:1em;width:1.25em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;\"><path d=\"M72 88a56 56 0 1 1 112 0A56 56 0 1 1 72 88zM64 245.7C54 256.9 48 271.8 48 288s6 31.1 16 42.3V245.7zm144.4-49.3C178.7 222.7 160 261.2 160 304c0 34.3 12 65.8 32 90.5V416c0 17.7-14.3 32-32 32H96c-17.7 0-32-14.3-32-32V389.2C26.2 371.2 0 332.7 0 288c0-61.9 50.1-112 112-112h32c24 0 46.2 7.5 64.4 20.3zM448 416V394.5c20-24.7 32-56.2 32-90.5c0-42.8-18.7-81.3-48.4-107.7C449.8 183.5 472 176 496 176h32c61.9 0 112 50.1 112 112c0 44.7-26.2 83.2-64 101.2V416c0 17.7-14.3 32-32 32H480c-17.7 0-32-14.3-32-32zm8-328a56 56 0 1 1 112 0A56 56 0 1 1 456 88zM576 245.7v84.7c10-11.3 16-26.1 16-42.3s-6-31.1-16-42.3zM320 32a64 64 0 1 1 0 128 64 64 0 1 1 0-128zM240 304c0 16.2 6 31 16 42.3V261.7c-10 11.3-16 26.1-16 42.3zm144-42.3v84.7c10-11.3 16-26.1 16-42.3s-6-31.1-16-42.3zM448 304c0 44.7-26.2 83.2-64 101.2V448c0 17.7-14.3 32-32 32H288c-17.7 0-32-14.3-32-32V405.2c-37.8-18-64-56.5-64-101.2c0-61.9 50.1-112 112-112h32c61.9 0 112 50.1 112 112z\"/></svg>`{=html}'\nsubtitle: \"MSSC 6250 Statistical Machine Learning\"\nauthor: \"Dr. Cheng-Han Yu <br> Department of Mathematical and Statistical Sciences <br> Marquette University\"\n# date: \"January 08 2024\"\n# macros: _macros.tex # import a list of TeX/LaTeX definitions\nformat: \n  revealjs:\n    html-math-method:\n      method: mathjax\n      url: \"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\"\n    # include-in-header:\n    #     - \"macros.tex\"\n    highlight-style: github\n    code-block-bg: true\n    self-contained: false\n    slide-number: c/t\n    incremental: false\n    width: 1800\n    height: 1000\n    margin: 0.05\n    logo: \"https://upload.wikimedia.org/wikipedia/commons/e/e8/Marquette_Golden_Eagles_logo.svg\"\n    footer: \"[mssc6250-s24.github.io/website](https://mssc6250-s24.github.io/website/)\"\n    theme: [\"simple\", \"styles.scss\"]\n    echo: false\n    multiplex: true\n    code-link: true\n    fig-cap-location: bottom\n    fig-align: center\n    transition: none ## fade slide convex concave zoom\n    title-slide-attributes:\n      data-background-color: \"#447099\"\n      # data-background-image: images/paper-texture.jpg\n      # data-background-size: cover\n      # data-background-color: \"#698ED5\"\neditor: source\nexecute:\n  freeze: true\n  cache: true\n  fig-align: center\n---\n\n\n\n# {visibility=\"hidden\"}\n\n\n\n\\def\\bg{\\mathbf{g}}\n\\def\\bu{\\mathbf{u}}\n\\def\\bv{\\mathbf{v}}\n\\def\\bw{\\mathbf{w}}\n\\def\\bx{\\mathbf{x}}\n\\def\\by{\\mathbf{y}}\n\\def\\bbeta{\\boldsymbol \\beta}\n\\def\\btheta{\\boldsymbol \\theta}\n\\def\\bmu{\\boldsymbol \\mu}\n\\def\\bH{\\mathbf{H}}\n\\def\\bI{\\mathbf{I}}\n\\def\\bS{\\mathbf{S}}\n\\def\\bW{\\mathbf{W}}\n\\def\\bX{\\mathbf{X}}\n\\def\\T{\\text{T}}\n\\def\\E{\\text{E}}\n\\def\\cov{\\mathrm{Cov}}\n\\def\\cor{\\mathrm{Corr}}\n\\def\\var{\\mathrm{Var}}\n\\DeclareMathOperator*{\\argmin}{arg\\,min}\n\\def\\Trace{\\text{Trace}}\n\n\n\n\n\n\n\n<!-- # Nonparametric Methods {background-color=\"#447099\"} -->\n\n## Nonparametric Examplar-based Methods\n\n- So far we have mostly focused on parametric models, either unconditional $p({\\bf y} \\mid \\btheta)$ or conditional $p({\\bf y} \\mid \\bx, \\btheta)$, where $\\btheta$ is a fixed-dimensional vector of parameters. ^[For example, $\\beta$ coefficients in linear regression.]\n\n- The parameters are estimated from the training set $\\mathcal{D} = \\{(\\bx_i, \\by_i)\\}_{i=1}^n$ but after model fitting, the data is not used anymore.\n\n. . .\n\n- The nonparametric models that *keep the training data around at the test time* are called **examplar-based models**, **instance-based learning** or **memory-based learning**.\n  + *K-nearest neighbors classification and regression*\n  + Kernel regression\n  + Local regression (LOESS)\n  + Kernel density estimation\n\n. . .\n\n- The examplar-based models usually perform a **local averaging** technique based on the similarity or distance between a test input $\\bx_0$ and each of the training inputs $\\bx_i$.\n\n<!-- # K-nearest Neighbors -->\n\n\n## K-nearest Neighbor Regression\n\n\n- **K-nearest neighbor (KNN)** is a nonparametric method.\n\n- It can be used for both regression and classification.\n\n- In KNN, we don't have parameters $\\bbeta$, and $f(\\bx_0) = \\bx_0'\\bbeta$ in regression.\n\n- We directly estimate $f(\\bx_0)$ using our *examples* or *memory*.^[$\\widehat{y}_0 = \\widehat{f}(x_0)$.]\n\n$$ \\widehat{y}_0 = \\frac{1}{k} \\sum_{x_i \\in N_k(x_0)} y_i,$$ \nwhere the neighborhood of $x_0$, $N_k(x_0)$, defines the *$k$ training data points that are closest to $x_0$*.\n\n- Closeness (Similarity) is defined using a distance measure, such as the Euclidean distance.\n\n## 1-Nearest Neighbor Regression\n\n\n::: {.cell layout-align=\"center\" hash='11-knn_cache/revealjs/unnamed-chunk-2_20030229022bcee554b2705c41be9399'}\n::: {.cell-output-display}\n![](images/11-knn/unnamed-chunk-2-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n## Tuning $k$\n\n- $y_i = 2\\sin(x_i) + \\epsilon_i, \\quad \\epsilon_i \\stackrel{iid}{\\sim} N(0, 1), \\quad i = 1, \\dots, 200$\n\n\n::: {.cell layout-align=\"center\" hash='11-knn_cache/revealjs/unnamed-chunk-3_05f4d348ce2bd79180fc11911727fef5'}\n\n:::\n\n::: {.cell layout-align=\"center\" hash='11-knn_cache/revealjs/unnamed-chunk-4_cf524482d90162429e01fbcce076a5cb'}\n::: {.cell-output-display}\n![](images/11-knn/unnamed-chunk-4-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\n\n::: notes\n- put all weights on one single training point. The predictive value at some test $x$ relies solely on one single training point that is closest to $x$.\n:::\n\n\n\n\n## The Bias-variance Trade-off\n\n\n::: {.cell layout-align=\"center\" hash='11-knn_cache/revealjs/unnamed-chunk-5_15f50f3fc52a5e3e3b734ad81fc7005e'}\n::: {.cell-output-display}\n![](images/11-knn/unnamed-chunk-5-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\n\n:::notes\nIf we consider different values of $k$, we can observe the trade-off between bias and variance. \n:::\n\n\n## Bias-Variance Trade-Off\n\n\\begin{aligned}\n\\E\\Big[ \\big( Y - \\widehat f(x_0) \\big)^2 \\Big]\n&= \\underbrace{\\E\\Big[ ( Y - f(x_0))^2 \\big]}_{\\text{Irreducible Error}} +\n\\underbrace{\\Big(f(x_0) - \\E[\\widehat f(x_0)]\\Big)^2}_{\\text{Bias}^2} + \n\\underbrace{\\E\\Big[ \\big(\\widehat f(x_0) - \\E[\\widehat f(x_0)] \\big)^2 \\Big]}_{\\text{Variance}}\n\\end{aligned}\n  \n* As $k \\uparrow$, bias $\\uparrow$ and variance $\\downarrow$ (smoother)\n* As $k \\downarrow$, bias $\\downarrow$ and variance $\\uparrow$ (more wiggly)\n  \n\n\n::: notes\nwhen k is small, the estimated model is unstable.\nAlso, each time we observe a new training data, we may get a very different estimation. (due to the closest sample and )\nWhen k is large, the estimated model eventually deviates (systematically) from the truth.\nIf we use more “neighbouring” points, say k, the variance would reduce to approximately σ2/k. But the bias2 will increase as neighbours are far away from x0.\nk determines the model complexity\n:::\n\n\n\n## Degrees of Freedom\n\n- $k$ determines the model complexity and degrees of freedom (df).\n\n- In general, the df can be defined as \n\n$$\\text{df}(\\hat{f}) = \\frac{1}{\\sigma^2}\\text{Trace}\\left( \\cov(\\hat{\\by}, \\by)\\right)= \\frac{1}{\\sigma^2}\\sum_{i=1}^n \\cov(\\hat{y}_i, y_i)$$\n\n- $k = 1$: $\\hat{f}(x_i) = y_i$ and $\\text{df}(\\hat{f}) = n$\n\n- $k = n$: $\\hat{f}(x_i) = \\bar{y}$ and $\\text{df}(\\hat{f}) = 1$\n\n- For general $k$, $\\text{df}(\\hat{f}) = n/k$.\n\n. . .\n\n- Linear regression with $p$ coefficients: $\\text{df}(\\hat{f}) = \\text{Trace}\\left( {\\bf H} \\right) = p$\n\n- For any linear smoother $\\hat{\\by} = {\\bf S} \\by$, $\\text{df}(\\hat{f}) = \\text{Trace}({\\bf S})$.\n\n\n## K-nearest Neighbor Classification\n\n- Instead of taking average in regression, KNN classification uses *majority voting*:\n\n:::{.center}\n[*Look for the most popular class label among its neighbors*.]{.green}\n:::\n\n- 1NN decision boundary is a **Voronoi diagram**.\n\n:::{.center}\n\n::: {.cell layout-align=\"center\" hash='11-knn_cache/revealjs/unnamed-chunk-6_94182df85462664c64e906d6ab299ee6'}\n::: {.cell-output-display}\n![](images/11-knn/unnamed-chunk-6-1.png){fig-align='center' width=70%}\n:::\n:::\n\n:::\n\n::: notes\n- Voronoi tessellation. https://en.wikipedia.org/wiki/Voronoi_diagram\n- \n:::\n\n\n## Example\n\n<!-- - An artificial data with 200 binary labels. -->\n\n- The KNN decision boundary is nonlinear.\n\n- R: `class::knn()`, [`kknn::kknn()`](https://github.com/KlausVigo/kknn), [`parsnip::nearest_neighbor()`](https://parsnip.tidymodels.org/reference/nearest_neighbor.html)\n\n- Python: [`from sklearn.neighbors import KNeighborsClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier)\n\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\n::: {.cell layout-align=\"center\" hash='11-knn_cache/revealjs/unnamed-chunk-7_986c972a3234a069f5861830c6cbda7f'}\n::: {.cell-output-display}\n![](images/11-knn/unnamed-chunk-7-1.png){fig-align='center' width=70%}\n:::\n:::\n\n:::\n\n\n::: {.column width=\"50%\"}\n\n\n\n\n\n::: {.cell layout-align=\"center\" hash='11-knn_cache/revealjs/unnamed-chunk-8_57de8e5a74ea7add8e19c6731308cb45'}\n::: {.cell-output-display}\n![](images/11-knn/unnamed-chunk-8-1.png){fig-align='center' width=70%}\n:::\n:::\n\n:::\n::::\n\n\n## Example\n\n\n:::: {.columns}\n\n::: {.column width=\"33%\"}\n\n::: {.cell layout-align=\"center\" hash='11-knn_cache/revealjs/unnamed-chunk-9_660b62a3d6f568ded91a8ef780bd542b'}\n::: {.cell-output-display}\n![](images/11-knn/unnamed-chunk-9-1.png){fig-align='center' width=100%}\n:::\n:::\n\n:::\n\n::: {.column width=\"33%\"}\n\n::: {.cell layout-align=\"center\" hash='11-knn_cache/revealjs/unnamed-chunk-10_09171ded76e63ce03cc255170ff5c5ac'}\n::: {.cell-output-display}\n![](images/11-knn/unnamed-chunk-10-1.png){fig-align='center' width=100%}\n:::\n:::\n\n:::\n\n::: {.column width=\"33%\"}\n\n::: {.cell layout-align=\"center\" hash='11-knn_cache/revealjs/unnamed-chunk-11_1ad3f720c1312472acb1ae9e3add1d90'}\n::: {.cell-output-display}\n![](images/11-knn/unnamed-chunk-11-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n:::\n::::\n\n\n\n## Confusion Matrix\n\n\n::: {.cell layout-align=\"center\" hash='11-knn_cache/revealjs/unnamed-chunk-12_52b240264fae08d0bea65deeb26286ec'}\n\n```{.r .cell-code}\n  knn_fit <- class::knn(train = x, test = x, cl = y, k = 15)\n  caret::confusionMatrix(table(knn_fit, y))\n```\n\n::: {.cell-output .cell-output-stdout}\n```{.my_class800}\nConfusion Matrix and Statistics\n\n       y\nknn_fit  0  1\n      0 82 13\n      1 18 87\n                                        \n               Accuracy : 0.845         \n                 95% CI : (0.787, 0.892)\n    No Information Rate : 0.5           \n    P-Value [Acc > NIR] : <2e-16        \n                                        \n                  Kappa : 0.69          \n                                        \n Mcnemar's Test P-Value : 0.472         \n                                        \n            Sensitivity : 0.820         \n            Specificity : 0.870         \n         Pos Pred Value : 0.863         \n         Neg Pred Value : 0.829         \n             Prevalence : 0.500         \n         Detection Rate : 0.410         \n   Detection Prevalence : 0.475         \n      Balanced Accuracy : 0.845         \n                                        \n       'Positive' Class : 0             \n                                        \n```\n:::\n:::\n\n\n## Choosing K\n\n\n::: {.cell layout-align=\"center\" hash='11-knn_cache/revealjs/unnamed-chunk-13_0bc36e18412d1cfa0f39cd3414948af4'}\n\n```{.r .cell-code  code-fold=\"true\"}\nset.seed(2023)\nlibrary(caret)\ncontrol <- trainControl(method = \"cv\", number = 10)\nknn_cvfit <- train(y ~ ., method = \"knn\", \n                   data = data.frame(\"x\" = x, \"y\" = as.factor(y)),\n                   tuneGrid = data.frame(k = seq(1, 40, 1)),\n                   trControl = control)\npar(mar = c(4, 4, 0, 0))\nplot(knn_cvfit$results$k, 1 - knn_cvfit$results$Accuracy,\n     xlab = \"K\", ylab = \"Classification Error\", type = \"b\",\n     pch = 19, col = 2)\n```\n\n::: {.cell-output-display}\n![](images/11-knn/unnamed-chunk-13-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n## Best K {visibility=\"hidden\"}\n\n::: {.cell layout-align=\"center\" hash='11-knn_cache/revealjs/unnamed-chunk-14_0c12ec0b6f98ea8fa34c933f31ccf6f6'}\n::: {.cell-output .cell-output-stdout}\n```\n  k\n4 4\n```\n:::\n:::\n\n\n:::: {.columns}\n::: {.column width=\"50%\"}\n\n::: {.cell layout-align=\"center\" hash='11-knn_cache/revealjs/unnamed-chunk-15_bbf81b195043ca4bd9f2ee27e2803d8d'}\n::: {.cell-output-display}\n![](images/11-knn/unnamed-chunk-15-1.png){fig-align='center' width=100%}\n:::\n:::\n\n:::\n\n::: {.column width=\"50%\"}\n\n\n::: {.cell layout-align=\"center\" hash='11-knn_cache/revealjs/unnamed-chunk-16_c3394c6a368756ba75a0dafcd251bdb7'}\n::: {.cell-output .cell-output-stdout}\n```{.my_class800}\nConfusion Matrix and Statistics\n\n       y\nknn_fit  0  1\n      0 83 11\n      1 17 89\n                                        \n               Accuracy : 0.86          \n                 95% CI : (0.804, 0.905)\n    No Information Rate : 0.5           \n    P-Value [Acc > NIR] : <2e-16        \n                                        \n                  Kappa : 0.72          \n                                        \n Mcnemar's Test P-Value : 0.345         \n                                        \n            Sensitivity : 0.830         \n            Specificity : 0.890         \n         Pos Pred Value : 0.883         \n         Neg Pred Value : 0.840         \n             Prevalence : 0.500         \n         Detection Rate : 0.415         \n   Detection Prevalence : 0.470         \n      Balanced Accuracy : 0.860         \n                                        \n       'Positive' Class : 0             \n                                        \n```\n:::\n:::\n\n:::\n::::\n\n## Scaling and Distance Measures\n\n- By default, we use Euclidean distance ($\\ell_2$ norm).\n\n:::{.small}\n$$d^2(\\bu, \\bv) = \\lVert \\bu - \\bv \\rVert_2^2 = \\sum_{j=1}^p (u_j - v_j)^2$$\n:::\n\n- This measure is not *scale invariant*: Multiplying the data with a factor changes the distance!\n\n. . .\n\n- Often consider a normalized version:\n\n:::{.small}\n$$d^2(\\bu, \\bv) = \\sum_{j=1}^p \\frac{(u_j - v_j)^2}{\\sigma_j^2}$$\n:::\n\n. . .\n\n- __Mahalanobis distance__ takes the covariance structure into account\n\n:::{.small}\n$$d^2(\\bu, \\bv) = (\\bu - \\bv)' \\Sigma^{-1} (\\bu - \\bv),$$\n:::\n\n- If $\\Sigma = \\bI$, Mahalanobis = Euclidean\n- If $\\Sigma = diag(\\sigma^2_1, \\dots, \\sigma^2_p)$, Mahalanobis = normalized version\n\n## Mahalanobis distance\n\n- Red and green points have the same Euclidean distance to the center.\n\n- The red point is farther away from the center in terms of Mahalanobis distance.\n\n\n\n::: {.cell layout-align=\"center\" hash='11-knn_cache/revealjs/unnamed-chunk-17_87a77f8d13bc9257e13eae4ef53e86fe'}\n::: {.cell-output-display}\n![](images/11-knn/unnamed-chunk-17-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n::: notes\nIn the following plot, the red cross and orange cross have the same Euclidean distance to the center. However, the red cross is more of a \"outlier\" based on the joint distribution. The Mahalanobis distance would reflect this. \n:::\n\n\n## Example: Image Data [`ElemStatLearn::zip.train`](https://hastie.su.domains/ElemStatLearn/)\n\n- Digits 0-9 scanned from envelopes by the U.S. Postal Service\n\n- $16 \\times 16$ pixel images, totally $p=256$ variables\n\n- At each pixel, we have the gray scale as the numerical value\n\n- 1NN with Euclidean distance gives 5.6% error rate\n\n- 1NN with [tangent distance]{.green} (Simard et al., 1993) gives 2.6% error\n\n\n::: {.cell layout-align=\"center\" hash='11-knn_cache/revealjs/unnamed-chunk-18_ed73dd9895961cb19dcca6650ba7f1ab'}\n::: {.cell-output-display}\n![](images/11-knn/unnamed-chunk-18-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\n\n## Example: 3NN on Image Data\n\n\n::: {.cell layout-align=\"center\" hash='11-knn_cache/revealjs/unnamed-chunk-19_c6864482b9014fc4e214b94b22d7004a'}\n\n```{.r .cell-code}\n  # fit 3nn model and calculate the error\n  knn.fit <- class::knn(zip.train[, 2:257], zip.test[, 2:257], zip.train[, 1], k = 3)\n  # overall prediction error\n  mean(knn.fit != zip.test[, 1])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.0543\n```\n:::\n:::\n\n::: {.cell layout-align=\"center\" hash='11-knn_cache/revealjs/unnamed-chunk-20_dbca6637b352e2053fa45ddc6ee14185'}\n\n```{.r .cell-code}\n  # the confusion matrix\n  table(knn.fit, zip.test[, 1])\n```\n\n::: {.cell-output .cell-output-stdout}\n```{.my_class500}\n       \nknn.fit   0   1   2   3   4   5   6   7   8   9\n      0 355   0   7   2   0   4   3   0   4   1\n      1   0 258   0   0   2   0   0   1   0   0\n      2   3   0 183   2   0   3   1   1   0   0\n      3   0   0   1 153   0   3   0   1   3   0\n      4   0   3   1   0 182   0   2   4   0   3\n      5   0   0   0   6   2 145   1   0   2   1\n      6   0   2   1   0   2   0 163   0   0   0\n      7   0   1   2   1   3   0   0 138   1   4\n      8   0   0   3   0   1   1   0   1 153   0\n      9   1   0   0   2   8   4   0   1   3 168\n```\n:::\n:::\n\n\n\n## Example: 3NN on Image Data\n\n\n::: {.cell layout-align=\"center\" hash='11-knn_cache/revealjs/unnamed-chunk-21_10d16ce8c9ba23aa2a4d0cad58fd5aa3'}\n::: {.cell-output-display}\n![](images/11-knn/unnamed-chunk-21-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\n\n\n\n## Computational Issues\n- Need to store the entire training data for prediction. (Lazy learner)\n\n- Needs to calculate the distance from $x_0$ to all training sample and sort them.^[R [`FNN`](https://cran.r-project.org/web/packages/FNN/FNN.pdf) package for faster computations when $n$ is large.]\n\n- Distance measures may affect accuracy.\n\n::: notes\n$K$NN can be quite computationally intense for large sample size because to find the nearest neighbors, we need to calculate and compare the distances to each of the data point. In addition, it is not memory friendly because we need to store the entire training dataset for future prediction. In contrast, for linear model, we only need to store the estimated $\\bbeta$ parameters. Some algorithms have been developed to search for the neighbors more efficiently. You can try the `FNN` package for these faster computations when $n$ is large. \n:::\n\n\n## Curse of Dimensionality\n\n- KNN does does not work well in high-dimensional space ($p \\gg n$) due to **curse of dimensionality**.\n\n> *As $p$ increases, it's getting harder to find $k$ neighbors in the input space. KNN needs to explore a large range of values along each input dimension to grab the \"neighbors\".*\n\n- The \"neighbors\" of $x_0$ are in fact far away from $x_0$, and so they may not be good predictors about the behavior of the function at $x_0$.\n\n- The method is not local anymore despite the name \"nearest neighbor\"!\n\n- In high dimensions KNN often performs worse than linear regression.\n\n\n\n## Curse of Dimensionality {visibility=\"hidden\"}\n\n- Data points are uniformly spread out on $[0, 1]^p$.\n\n- In 10 dimensions we need to cover 80% of the range of each coordinate to capture 10% of the data.\n\n\n::: {.cell layout-align=\"center\" fig-cap-location='bottom' hash='11-knn_cache/revealjs/unnamed-chunk-22_f07b187851f0475369edc89dbaa2628d'}\n::: {.cell-output-display}\n![Source: ESL Fig. 2.6](./images/11-knn/curse.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n::: notes\n- The problem comes from the fact that the volume of space grows exponentially fast with dimension, so we may have to look quite far away in space to find our nearest neighbor.\n:::\n\n\n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}